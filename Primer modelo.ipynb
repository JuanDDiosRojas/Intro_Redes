{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer modelo\n",
    "Vamos a tomar un conjunto de datos creados de manera sintética y utilizaremos el descenso del gradiente para optimizar un modelo que se ajuste a ellos.\n",
    "Para el caso más sencillo utilizaremos una relación lineal entre las variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supondremos un modelo que depende de dos variables $f(x_1,x_2)=y$ con una relación lineal entre las variables de la manera \n",
    "$y=w_1x_1+w_2x_2+b$\n",
    "\n",
    "Supondremos que partimos de un conjunto de n datos, los cuales llamaremos ejemplos: de la forma \n",
    "$$y_1=w_1x_1^1+w_2x_1^2+b$$\n",
    "$$y_2=w_1x_2^1+w_2x_2^2+b$$\n",
    "$$...$$\n",
    "$$y_n=w_1x_n^1+w_2x_n^2+b$$\n",
    "\n",
    "$$Y=XW+b$$\n",
    "\n",
    "Con Y el vector que contiene a los $y_i$, X y W análogamente contienen a $w_i$ y a $x_i^j$\n",
    "\n",
    "Para entrenar este modelo vamos a generar definir un par de $w_1$ y $w_2$ y les agregaremos ruido aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trabajamos en el dominio [-10,10]\n",
    "#Incluimos a b en w, w=[w1,w2,b]\n",
    "def datos_prueba(w,n):\n",
    "    #n será el número de ejemplos\n",
    "    #generamos el dominio de los datos, aleatorios con distribución normal\n",
    "    X=np.random.normal(-10,10,(n,len(w)-1))\n",
    "    \n",
    "    X1=[]\n",
    "    for i in X:\n",
    "        i=np.append(i,1.0)\n",
    "        X1.append(i)\n",
    "    X1=np.array(X1)\n",
    "    Y = np.dot(X1, w) \n",
    "    Y=Y+np.random.normal(-1.0,0.8,Y.shape)\n",
    "    return X1,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minibatch\n",
    "Con el fin de ahorrar costo computacional sólo trabajaremos con un porcentaje del número total de ejemplos, a este subconjunto se le llama minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(size,X,Y):\n",
    "    n=len(X)\n",
    "    #tomamos la lista de índices de tamaño n\n",
    "    indices=np.arange(0,n)\n",
    "    indices=list(indices)\n",
    "    #Tomamos una lista aleatoria de índices de tamaño=size\n",
    "    ibatch=random.sample(indices, size)\n",
    "    Xbatch=[]\n",
    "    Ybatch=[]\n",
    "    #Generamos las nuevas listas random\n",
    "    for i in ibatch:\n",
    "        Xbatch.append(X[i])\n",
    "        Ybatch.append(Y[i])\n",
    "        \n",
    "    return np.array(Xbatch),np.array(Ybatch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definiendo la función error\n",
    "Para calcular el error en nuestro modelo de aproximación debemos calcular el error de aproximación por cada ejemplo y para el conjunto completo: la suma de estos.\n",
    "Es decir la función de error para un conjunto de n ejemplos será:\n",
    "$$Error=E(W,b)=\\sum_{i=1}^{n}l_i(W,b)$$\n",
    "\n",
    "Donde $l_i$ será el error de cada ejemplo, en este caso se tomará el error cuadrático medio.\n",
    "Entonces:\n",
    "$$l_i=\\frac{1}{2}(\\bar{y_i}-y_i)^2$$\n",
    "\n",
    "Donde $\\bar{y_i} será el valor estimado por nuestro modelo$\n",
    "entonces para este caso la función error será \n",
    "$$l_i=\\frac{1}{2}((w_1x_1^i+w_2x_2^i+b)-y_i)²$$\n",
    "\n",
    "Y el error total\n",
    "$$E(W,b)=\\sum_{i=1}^{n}\\frac{1}{2}((w_1x_1^i+w_2x_2^i+b)-y_i)²$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificaremos las variables para meter b en W, agregamos b a w\n",
    "y añadimos una columna de \"1\" a X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aprendizaje\n",
    "Con ayuda del descenso del gradiente podemos encontrar los valores que nos otorguen el modelo esperado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_grad(f,X0,eta):\n",
    "   \n",
    "    #definimos las derivadas parciales de una función de R^n a R\n",
    "    #si X=(x1,x2,...,xk,...xn), debemos indicar con k respecto a cuál variable derivar\n",
    "    def partial(g,k,X):\n",
    "        h=1e-9\n",
    "        Y=np.copy(X)\n",
    "        X[k-1]=X[k-1]+h\n",
    "        dp=(g(X)-g(Y))/h\n",
    "        return dp\n",
    "    #Ahora definimos la función que nos dará el gradiente\n",
    "    def grad(f,X):\n",
    "        grd=[]\n",
    "        for i in np.arange(0,len(X)):\n",
    "            ai=partial(f,i+1,X)\n",
    "            grd.append(ai)\n",
    "        return grd\n",
    "    #Ahora se hacen las iteraciones\n",
    "    i=0\n",
    "    while True:\n",
    "        i=i+1\n",
    "        X0=X0-eta*np.array(grad(f,X0))\n",
    "        if np.linalg.norm(grad(f,X0))<10e-8 or i>40: break\n",
    "    return X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=[3,5,7] #w real de la forma [w1,w2,b] \n",
    "X1,Y1=datos_prueba(w,100)# datos sintéticos\n",
    "\n",
    "def error(W):\n",
    "    X,Y=minibatch(80,X1,Y1)\n",
    "    #suma del error medio cuadrático de cada ejemplo\n",
    "    s=0\n",
    "    for i in range(0,len(Y)):\n",
    "        l=0.5*(np.dot(X[i],W)-Y[i])**2\n",
    "        s=s+l\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-028302cd328d>:9: RuntimeWarning: overflow encountered in double_scalars\n",
      "  l=0.5*(np.dot(X[i],W)-Y[i])**2\n",
      "<ipython-input-7-731a90d1388d>:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dp=(g(X)-g(Y))/h\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descenso_grad(error,[1,1,1],0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    " def partial(g,k,X):\n",
    "        h=1e-9\n",
    "        Y=np.copy(X)\n",
    "        X[k-1]=X[k-1]+h\n",
    "        dp=(g(X)-g(Y))/h\n",
    "        return dp\n",
    "    #Ahora definimos la función que nos dará el gradiente\n",
    "def grad(f,X):\n",
    "    grd=[]\n",
    "    for i in np.arange(0,len(X)):\n",
    "        ai=partial(f,i+1,X)\n",
    "        grd.append(ai)\n",
    "    return grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-76793.5998737812, -118223.89205917715, 5791.254807263613]\n",
      "[23039.07996214 35468.20254235 -1736.34151758]\n"
     ]
    }
   ],
   "source": [
    "W=[1,1,1]\n",
    "error(W)\n",
    "#for i in range(1):\n",
    "print(grad(error,W))\n",
    "W=W-0.3*np.array(grad(error,W))\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-76793.5998737812, -118223.89205917715, 5791.254807263613]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(error,[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
